{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cef3d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, time\n",
    "\n",
    "def remove_previous_audio_chunks(\n",
    "        dir_path: str,\n",
    "):\n",
    "    try:\n",
    "        if os.path.exists(dir_path):\n",
    "            shutil.rmtree(dir_path)\n",
    "            # time.sleep(0.5)\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "            print(f\"Removed previous audio chunks in {dir_path}\")\n",
    "        else:\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "            print(f\"Directory {dir_path} created\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error removing directory {dir_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73172025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kokoro import KPipeline\n",
    "import soundfile as sf\n",
    "\n",
    "# ðŸ‡ºðŸ‡¸ 'a' => American English, ðŸ‡¬ðŸ‡§ 'b' => British English\n",
    "# ðŸ‡ªðŸ‡¸ 'e' => Spanish es\n",
    "# ðŸ‡«ðŸ‡· 'f' => French fr-fr\n",
    "# ðŸ‡®ðŸ‡³ 'h' => Hindi hi\n",
    "# ðŸ‡®ðŸ‡¹ 'i' => Italian it\n",
    "# ðŸ‡¯ðŸ‡µ 'j' => Japanese: pip install misaki[ja]\n",
    "# ðŸ‡§ðŸ‡· 'p' => Brazilian Portuguese pt-br\n",
    "# ðŸ‡¨ðŸ‡³ 'z' => Mandarin Chinese: pip install misaki[zh]\n",
    "# https://github.com/nazdridoy/kokoro-tts\n",
    "\n",
    "def create_audio_chunks(\n",
    "        text: str,\n",
    "        path: str,\n",
    "        lang_code: str = 'a', # ðŸ‡¬ðŸ‡§ British English\n",
    "        repo_id: str = 'hexgrad/Kokoro-82M',\n",
    "        voice: str = 'am_adam', #  American English\n",
    "):\n",
    "    pipeline = KPipeline(\n",
    "        lang_code=lang_code,\n",
    "        repo_id=repo_id,\n",
    "        # device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    ) # <= make sure lang_code matches voice, reference above.\n",
    "\n",
    "    # Generate, display, and save audio files in a loop.\n",
    "    generator = pipeline(\n",
    "        text, \n",
    "        voice='am_adam', # <= change voice here\n",
    "        speed=1,\n",
    "        split_pattern=r'\\n+',\n",
    "    )\n",
    "\n",
    "    for i, (_,_,audio) in enumerate(generator):\n",
    "        sf.write(f'{path}/{i}.wav', audio, 24000) # save each audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c568bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "def merge_wav_files_pydub(directory, output_path):\n",
    "    # Get all wav files in the directory\n",
    "    wav_files = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        file_path = os.path.join(directory, f\"{i}.wav\")\n",
    "        if os.path.exists(file_path):\n",
    "            wav_files.append(file_path)\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    if not wav_files:\n",
    "        print(\"No wav files found.\")\n",
    "        return\n",
    "    \n",
    "    # Load the first file\n",
    "    combined = AudioSegment.from_wav(wav_files[0])\n",
    "    \n",
    "    # Append all other files\n",
    "    for file_path in wav_files[1:]:\n",
    "        audio = AudioSegment.from_wav(file_path)\n",
    "        combined += audio\n",
    "    \n",
    "    # Export the combined audio\n",
    "    combined.export(output_path, format=\"mp3\")\n",
    "    print(f\"Successfully merged {len(wav_files)} files into {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "734de4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed previous audio chunks in ./audio_chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasun/Desktop/ADHYAYAN_MITRA/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n",
      "/home/prasun/Desktop/ADHYAYAN_MITRA/.venv/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully merged 2 files into merged_output.wav\n"
     ]
    }
   ],
   "source": [
    "audio_chunk_dir = \"./audio_chunks\"\n",
    "remove_previous_audio_chunks(dir_path=audio_chunk_dir)\n",
    "transcript ='''\n",
    "    The sky above the port was the color of television, tuned to a dead channel.\n",
    "    [Kokoro](/kËˆOkÉ™É¹O/) is an open-weight TTS model with 82 million parameters. Despite its lightweight architecture, it delivers comparable quality to larger models while being significantly faster and more cost-efficient. With Apache-licensed weights, [Kokoro](/kËˆOkÉ™É¹O/) can be deployed anywhere from production environments to personal projects.\n",
    "'''\n",
    "create_audio_chunks(\n",
    "    text=transcript,\n",
    "    path=audio_chunk_dir,\n",
    ")\n",
    "merge_wav_files_pydub(audio_chunk_dir, \"merged_output.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2404c03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gtts import gTTS\n",
    "# # gTTS is a Python library and CLI tool to interface with Google Translate's text-to-speech API.\n",
    "# # It uses the same API as Google Translate, which means it can be used to generate speech in multiple languages.\n",
    "# # gTTS is a simple and easy-to-use library that allows you to convert text to speech in a variety of languages.\n",
    "# # It supports multiple languages, including English, Spanish, French, German, Italian, Portuguese, Dutch, Russian, Chinese, Japanese, and Korean.\n",
    "# # gTTS is a great tool for generating speech in multiple languages, and it can be used to create audio files for a variety of applications.\n",
    "\n",
    "# text = text\n",
    "# tts = gTTS(text, lang='en', slow=False)\n",
    "# tts.save('gtts.mp3')\n",
    "# # Play the audio file\n",
    "# display(Audio('gtts.mp3', autoplay=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
